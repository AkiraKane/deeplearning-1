{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "# Download MNIST data\n",
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_mnist(y, iterations=1000, batch_size=100):\n",
    "    # Define loss and optimizer\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "    # Train the model\n",
    "    tf.initialize_all_variables().run()\n",
    "    for i in range(iterations):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        train_step.run({x: batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "\n",
    "    # Test the model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    validation_accuracy = accuracy.eval({x: mnist.validation.images, y_: mnist.validation.labels, keep_prob: 1.0})\n",
    "    test_accuracy = accuracy.eval({x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "    return validation_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grid search for hyper parameters\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "def optimize_mnist(get_model, *hyperparameters):\n",
    "    print('validation, test, hyperparameter')\n",
    "    best = None\n",
    "    \n",
    "    for hyperparameter in itertools.product(*hyperparameters):\n",
    "        model = get_model(*hyperparameter)\n",
    "        validation_accuracy, test_accuracy = train_mnist(model)\n",
    "        print(validation_accuracy, test_accuracy, hyperparameter)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if best is None or validation_accuracy > best[0]:\n",
    "            best = (validation_accuracy, test_accuracy, hyperparameter)\n",
    "    print('best setting')\n",
    "    print(*best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, test, hyperparameter\n",
      "0.9158 0.9129 (0.01, 0.0)\n",
      "0.9148 0.9141 (0.01, 0.01)\n",
      "0.9162 0.9146 (0.01, 0.1)\n",
      "0.9156 0.9135 (0.01, 1.0)\n",
      "0.9134 0.9111 (0.1, 0.0)\n",
      "0.9144 0.9126 (0.1, 0.01)\n",
      "0.9152 0.9096 (0.1, 0.1)\n",
      "0.911 0.9081 (0.1, 1.0)\n",
      "0.7544 0.7555 (1.0, 0.0)\n",
      "0.7462 0.7448 (1.0, 0.01)\n",
      "0.742 0.7302 (1.0, 0.1)\n",
      "0.7778 0.7843 (1.0, 1.0)\n",
      "best setting\n",
      "0.9162 0.9146 (0.01, 0.1)\n"
     ]
    }
   ],
   "source": [
    "# Linear softmax classifier\n",
    "def linear_model(stddev, b_init):\n",
    "    W = tf.Variable(tf.truncated_normal([784, 10], stddev=stddev))\n",
    "    b = tf.Variable(tf.constant(b_init, shape=[10]))\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    return y\n",
    "\n",
    "stddev = [0.01, 0.1, 1.0]\n",
    "b_init = [0.0, 0.01, 0.1, 1.0]\n",
    "optimize_mnist(linear_model, stddev, b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, test, hyperparameter\n",
      "0.951 0.9454 (100,)\n",
      "0.9686 0.9693 (1000,)\n",
      "0.9792 0.9747 (5000,)\n",
      "0.9754 0.9718 (10000,)\n",
      "best setting\n",
      "0.9792 0.9747 (5000,)\n"
     ]
    }
   ],
   "source": [
    "# neural network with one hidden layer\n",
    "stddev = 0.01\n",
    "b_init = 0.01\n",
    "\n",
    "def neural_network(h_size):\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, h_size], stddev=stddev))\n",
    "    b1 = tf.Variable(tf.constant(b_init, shape=[h_size]))\n",
    "    W2 = tf.Variable(tf.truncated_normal([h_size, 10], stddev=stddev))\n",
    "    b2 = tf.Variable(tf.constant(b_init, shape=[10]))\n",
    "    h = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    y = tf.nn.softmax(tf.matmul(h, W2) + b2)\n",
    "    return y\n",
    "\n",
    "h_size = [100, 1000, 5000, 10000]\n",
    "optimize_mnist(neural_network, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, test, hyperparameter\n",
      "0.9762 0.9738 (1000, 1000)\n",
      "0.975 0.9746 (1000, 5000)\n",
      "0.976 0.9733 (5000, 1000)\n",
      "0.9742 0.9734 (5000, 5000)\n",
      "best setting\n",
      "0.9762 0.9738 (1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# neural network with 2 hidden layers\n",
    "def deep_network(h1_size, h2_size):\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, h1_size], stddev=stddev))\n",
    "    b1 = tf.Variable(tf.constant(b_init, shape=[h1_size]))\n",
    "    W2 = tf.Variable(tf.truncated_normal([h1_size, h2_size], stddev=stddev))\n",
    "    b2 = tf.Variable(tf.constant(b_init, shape=[h2_size]))\n",
    "    W3 = tf.Variable(tf.truncated_normal([h2_size, 10], stddev=stddev))\n",
    "    b3 = tf.Variable(tf.constant(b_init, shape=[10]))\n",
    "    h1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "    y = tf.nn.softmax(tf.matmul(h2, W3) + b3)\n",
    "    return y\n",
    "\n",
    "h1_size = [1000, 5000]\n",
    "h2_size = [1000, 5000]\n",
    "\n",
    "optimize_mnist(deep_network, h1_size, h2_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, test, hyperparameter\n",
      "0.9436 0.9381 (100,)\n",
      "0.9718 0.9686 (1000,)\n",
      "0.9736 0.9711 (5000,)\n",
      "0.971 0.9696 (10000,)\n",
      "best setting\n",
      "0.9736 0.9711 (5000,)\n"
     ]
    }
   ],
   "source": [
    "# neural network  with one hidden layer and dropout\n",
    "def dropout(h_size):\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, h_size], stddev=stddev))\n",
    "    b1 = tf.Variable(tf.constant(b_init, shape=[h_size]))\n",
    "    W2 = tf.Variable(tf.truncated_normal([h_size, 10], stddev=stddev))\n",
    "    b2 = tf.Variable(tf.constant(b_init, shape=[10]))\n",
    "\n",
    "    h = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    h2 = tf.nn.dropout(h, keep_prob)\n",
    "    y = tf.nn.softmax(tf.matmul(h2, W2) + b2)\n",
    "    return y\n",
    "\n",
    "h_size = [100, 1000, 5000, 10000]\n",
    "optimize_mnist(dropout, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, test, hyperparameter\n",
      "0.9714 0.9727 (100,)\n",
      "0.98 0.9786 (500,)\n",
      "0.9816 0.9794 (1000,)\n",
      "0.9786 0.9765 (5000,)\n",
      "best setting\n",
      "0.9816 0.9794 (1000,)\n"
     ]
    }
   ],
   "source": [
    "# neural network with one hidden layer and batch normalization\n",
    "def batch_normalization(h_size):\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, h_size], stddev=stddev))\n",
    "    W2 = tf.Variable(tf.truncated_normal([h_size, 10], stddev=stddev))\n",
    "\n",
    "    z1 = tf.matmul(x, W1)\n",
    "    mean1, variance1 = tf.nn.moments(z1,[0])\n",
    "    offset1 = tf.Variable(tf.zeros([h_size]))\n",
    "    scale1 = tf.Variable(tf.ones([h_size]))\n",
    "    z1_ = tf.nn.batch_normalization(z1, mean1, variance1, offset1, scale1, 1e-3)\n",
    "    h1 = tf.nn.relu(z1_)\n",
    "    \n",
    "    z2 = tf.matmul(h1, W2)\n",
    "    mean2, variance2 = tf.nn.moments(z2,[0])\n",
    "    offset2 = tf.Variable(tf.zeros([10]))\n",
    "    scale2 = tf.Variable(tf.ones([10]))\n",
    "    z2_ = tf.nn.batch_normalization(z2, mean2, variance2, offset2, scale2, 1e-3)\n",
    "\n",
    "    y = tf.nn.softmax(z2_)\n",
    "    return y\n",
    "\n",
    "h_size = [100, 500, 1000, 5000]\n",
    "optimize_mnist(batch_normalization, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, test, hyperparameter\n",
      "0.981 0.9785 (2, 1000)\n",
      "0.9792 0.9787 (2, 2000)\n",
      "0.9832 0.9802 (2, 3000)\n",
      "0.9816 0.9805 (2, 4000)\n",
      "0.9778 0.9775 (3, 1000)\n",
      "0.98 0.9757 (3, 2000)\n",
      "0.9774 0.9774 (3, 3000)\n",
      "0.9794 0.9784 (3, 4000)\n",
      "0.9806 0.9766 (4, 1000)\n",
      "0.9798 0.9771 (4, 2000)\n",
      "0.9804 0.9788 (4, 3000)\n",
      "0.9804 0.9774 (4, 4000)\n",
      "0.974 0.9715 (5, 1000)\n",
      "0.9744 0.9718 (5, 2000)\n",
      "0.975 0.9732 (5, 3000)\n",
      "0.9744 0.9736 (5, 4000)\n",
      "best setting\n",
      "0.9832 0.9802 (2, 3000)\n"
     ]
    }
   ],
   "source": [
    "# deep neural network with batch normalization\n",
    "def deep_batch_normalization(layer_size, h_size):\n",
    "    h = [x]\n",
    "    W = []\n",
    "    offset = []\n",
    "    scale = []\n",
    "    \n",
    "    for i in range(layer_size):\n",
    "        W.append(tf.Variable(tf.truncated_normal([int(h[i].get_shape()[1]), h_size], stddev=stddev)))\n",
    "        z = tf.matmul(h[i], W[i])\n",
    "        mean, variance = tf.nn.moments(z,[0])\n",
    "        offset.append(tf.Variable(tf.zeros([h_size])))\n",
    "        scale.append(tf.Variable(tf.ones([h_size])))\n",
    "        z_ = tf.nn.batch_normalization(z, mean, variance, offset[i], scale[i], 1e-3)\n",
    "        h.append(tf.nn.relu(z_))\n",
    "    \n",
    "    W.append(tf.Variable(tf.truncated_normal([h_size, 10], stddev=stddev)))\n",
    "    z = tf.matmul(h[-1], W[-1])\n",
    "    mean, variance = tf.nn.moments(z, [0])\n",
    "    offset.append(tf.Variable(tf.zeros([10])))\n",
    "    scale.append(tf.Variable(tf.ones([10])))\n",
    "    z_ = tf.nn.batch_normalization(z, mean, variance, offset[-1], scale[-1], 1e-3)\n",
    "    \n",
    "    y = tf.nn.softmax(z_)\n",
    "    return y\n",
    "\n",
    "layer_size = [2, 3, 4, 5]\n",
    "h_size = [1000, 2000, 3000, 4000]\n",
    "optimize_mnist(deep_batch_normalization, layer_size, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.991, 0.9867)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = deep_batch_normalization(2, 1000)\n",
    "train_mnist(best_model, 10000, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
