{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.models.rnn.ptb import reader\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "batch_size = 16\n",
    "num_steps = 8\n",
    "hidden_size = 128\n",
    "vocab_size = 10000\n",
    "data_path = 'simple-examples/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "train_corpus, valid_corpus, test_corpus, _ = reader.ptb_raw_data(data_path)\n",
    "train_pairs = list(reader.ptb_iterator(train_corpus, batch_size, num_steps))\n",
    "test_pairs = list(reader.ptb_iterator(test_corpus, batch_size, num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create placeholder for training data\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "\n",
    "# Lookup word embedding\n",
    "embedding = tf.Variable(tf.truncated_normal([vocab_size, hidden_size], stddev=0.01))\n",
    "inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "\n",
    "# Create and connect RNN cells\n",
    "cell = tf.nn.rnn_cell.GRUCell(hidden_size)\n",
    "rnn_inputs = [tf.squeeze(input_, [1]) for input_ in tf.split(1, num_steps, inputs)]\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, state = tf.nn.rnn(cell, rnn_inputs, initial_state=initial_state)\n",
    "\n",
    "# Predict distribution over next word\n",
    "output = tf.reshape(tf.concat(1, outputs), [-1, hidden_size])\n",
    "softmax_w = tf.Variable(tf.truncated_normal([hidden_size, vocab_size], stddev=0.01))\n",
    "softmax_b = tf.Variable(tf.constant(0.01, shape=[vocab_size]))\n",
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "\n",
    "# Define loss function and optimize it\n",
    "loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "    [logits],\n",
    "    [tf.reshape(targets, [-1])],\n",
    "    [tf.ones([batch_size * num_steps], dtype=tf.float32)])\n",
    "\n",
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "train_step = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10000.3350706\n",
      "100 920.36028304\n",
      "200 678.291748702\n",
      "300 612.169591022\n",
      "400 821.56982151\n",
      "500 436.038341557\n",
      "600 331.660217599\n",
      "700 462.461936803\n",
      "800 593.215165007\n",
      "900 463.982041625\n",
      "1000 573.939940394\n",
      "1100 384.355951536\n",
      "1200 493.856857118\n",
      "1300 330.300567905\n",
      "1400 239.248514871\n",
      "1500 549.419468696\n",
      "1600 290.205821542\n",
      "1700 358.346958414\n",
      "1800 226.016831956\n",
      "1900 267.237587483\n",
      "2000 264.407071453\n",
      "2100 273.740536272\n",
      "2200 394.204222525\n",
      "2300 152.777649479\n",
      "2400 170.789594572\n",
      "2500 227.37268211\n",
      "2600 353.00619124\n",
      "2700 345.992778655\n",
      "2800 274.454156776\n",
      "2900 224.863056912\n",
      "3000 192.821429791\n",
      "3100 395.852972972\n",
      "3200 301.195303599\n",
      "3300 191.907102458\n",
      "3400 267.609683565\n",
      "3500 391.289654315\n",
      "3600 166.920947543\n",
      "3700 218.464467805\n",
      "3800 175.264956536\n",
      "3900 264.608622662\n",
      "4000 272.834466395\n",
      "4100 232.023988051\n",
      "4200 162.484073311\n",
      "4300 176.815870175\n",
      "4400 279.284039915\n",
      "4500 208.662333381\n",
      "4600 149.246814117\n",
      "4700 213.073690178\n",
      "4800 374.368109362\n",
      "4900 152.429168582\n",
      "5000 226.029765113\n",
      "5100 218.273603996\n",
      "5200 173.942582946\n",
      "5300 307.862825537\n",
      "5400 123.971791802\n",
      "5500 131.924879516\n",
      "5600 321.735967248\n",
      "5700 140.459287603\n",
      "5800 163.701302631\n",
      "5900 251.364747056\n",
      "6000 159.550732876\n",
      "6100 163.424817707\n",
      "6200 127.562275304\n",
      "6300 99.1324668314\n",
      "6400 158.815220952\n",
      "6500 231.047899409\n",
      "6600 96.3574476395\n",
      "6700 175.697226042\n",
      "6800 211.355966786\n",
      "6900 159.726954669\n",
      "7000 247.79123409\n",
      "7100 221.764202388\n",
      "7200 132.001081511\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "tf.initialize_all_variables().run()\n",
    "state_value = initial_state.eval()\n",
    "\n",
    "for i, (x, y) in enumerate(train_pairs):\n",
    "    cost_value, state_value, _ = session.run([cost, state, train_step],\n",
    "                                 {input_data: x, targets: y, initial_state: state_value})\n",
    "    if i % 1000 == 0:\n",
    "        perplexity = np.exp(cost_value / num_steps)\n",
    "        print(i, perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test perplexity 173.793656848\n"
     ]
    }
   ],
   "source": [
    "total_cost = 0\n",
    "state_value = initial_state.eval()\n",
    "\n",
    "for x, y in test_pairs:\n",
    "    cost_value, state_value = session.run([cost, state],\n",
    "                                 {input_data: x, targets: y, initial_state: state_value})\n",
    "    total_cost += cost_value\n",
    "    \n",
    "perplexity = np.exp(total_cost / (len(test_pairs) * num_steps))\n",
    "print('test perplexity', perplexity)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
